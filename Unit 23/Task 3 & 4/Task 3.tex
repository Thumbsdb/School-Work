\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[square,numbers]{natbib}
\usepackage{titlesec}
\usepackage{geometry}
\geometry{
a4paper,
total={170mm,257mm},
left=20mm,
top=20mm,
}

\title{Unit 23. (M1) Describe the drawbacks of an identified cognitive computing application}
\author{Chris Hadden}
\date{}
\bibliographystyle{abbrvnat}

\begin{document}

\maketitle

\section{Cost}\label{cost}
There are several factors to consider that could influence the costs associated with cognitive computing:

\subsection{Advantages}
The biggest advantage of using cognitive computing in healthcare is the same as in most other industries: leaner processes and more efficient use of staff. Cognitive AI is good at examining vast amounts of data and spotting patterns, similar to the tasks performed by a GP or nurse. Presenting AI with patient data allows it to identify health issues even before patients are aware of them. Preventive medicine like this could, for instance, "prevent 40\% of all cancers" \cite{prevention}.

Chatbots like WatsonX can also replace receptionists and take their responsibilities further by helping to diagnose patients. This could be seen as a cost-saving measure, although people whose jobs are under threat would consider it a disadvantage.

\subsection{Disadvantages}
Looking at the cost implications of adopting cognitive computing technology in healthcare, it may initially seem that they might be minimal due to the ease of understanding and implementing this technology. However, 

\begin{itemize}
\item \textbf{Development and Setup Costs:} Even if the concepts behind cognitive computing are straightforward, the development and deployment of these systems can be complex and costly. Developing algorithms that can process and analyze large datasets from patients, while ensuring they integrate well with existing healthcare systems, requires significant investment in both time and money.

\item \textbf{Training Costs:} Cognitive computing systems typically require substantial data to learn and make accurate predictions. Gaining that type of data in a GP or hospital may be inconvenient or time-consuming. Preparing this data, and training staff to use and maintain these systems, can be resource-intensive.

\item \textbf{Hardware and Infrastructure:} Hospitals and GP surgeries typically do not have access to large computing infrastructure, so they will need to either buy or rent it.

\item \textbf{Scalability:} Scaling cognitive computing solutions to handle larger datasets or additional tasks can require more resources. If this solution is used only in a GP surgery, this may not present a problem, but for something at the scale of the NHS, it could be very costly.
\end{itemize}

While cognitive computing technologies can offer significant advantages, such as increased efficiency, better data analysis, and decision-making capabilities, the costs associated with them are not solely dependent on their conceptual simplicity. Careful planning and analysis are required to understand the total cost of ownership and to ensure that the benefits justify the investments.

\section{Limited Analysis of Risk}
Analyzing risk is paramount when dealing with patients, as any mistakes can have a devastating impact.

Assessing risk accurately when implementing cognitive computing in a healthcare project can be challenging due to the complexity and unpredictability inherent in cognitive computing systems. A few key points to consider when dealing with risk analysis in cognitive computing projects are:

\begin{itemize}
	\item \textbf{Complexity and Predictability:} Cognitive computing systems, which often employ machine learning and artificial intelligence, can exhibit behaviors that are difficult to predict or explain, even to the developers. This unpredictability can make it challenging to fully assess all potential risks.
	\item \textbf{Data Dependency:} The effectiveness and behavior of cognitive computing systems heavily rely on the data they are trained on. Inaccurate, biased, or insufficient data can lead to unexpected outcomes, introducing risks that are hard to foresee. This puts the onus on patients to report their data correctly, and on healthcare practitioners to input it accurately and without bias.
	\item \textbf{Human Oversight:} While these systems are designed to operate automatically, human oversight remains crucial. AI should not be allowed to prescribe medicines or recommend courses of action that could exacerbate health issues.
\end{itemize}

To better manage these risks, we should consider the following approaches:
\begin{itemize}
	\item Thorough Testing and Validation
	\item Robust Data Governance: Implement strong data management practices
	\item Transparency and Documentation
\end{itemize}

\section{Security}
\subsection{Advantages}
Cognitive AI can have unexpected advantages regarding security. Being able to process large amounts of data allows an AI to correlate patient records with their normal behaviors. There are already many examples of this \cite{security} in other areas, and it is possible to see how this could extend into healthcare.

\subsection{Disadvantages}
The security of patients is very important. Cognitive computing, while powerful and beneficial for enhancing various business processes and decision-making, introduces specific security drawbacks:
\begin{itemize}
	\item \textbf{Data Privacy:} Patient confidentiality is paramount. Any leaks, intentional or not, will be devastating for patients. Current generations of chatbots have already been seen to leak data \cite{wired}.

	\item \textbf{Bias and Error Propagation:} Security flaws can also arise from the biases present in the training data or the algorithms themselves. If a cognitive computing system develops or propagates bias, it can lead to incorrect or harmful decisions, affecting the integrity and trustworthiness of the system. This could happen with healthcare training data where, for instance, only data from white people was used for training.

	\item \textbf{Compliance Risks:} Ensuring that cognitive computing systems comply with relevant laws and regulations, especially in health, could be hard as the AI may not be aware of them.
\end{itemize}

Addressing these security challenges requires a robust security framework tailored to the specific needs of cognitive computing technologies. This framework should include rigorous data protection measures, continuous vulnerability assessments, and proactive threat management strategies to mitigate the unique risks these systems present.

\section{Adoption}
Adoption in healthcare can be tricky. As seen from the Cost section \ref{cost}, where there was mention of replacing receptionists with a chatbot, those people concerned about losing their jobs will not want to adopt any AI in this form. One way to mitigate this is to retrain anyone whose job is at risk. Any adoption of cognitive AI will need human moderation, which could be an area for redeployment. Also, it is seen to be better practice that AI works with people and does not replace them. In this case, an AI could screen patients and pass them to a receptionist who decides what to do with them. This would free up receptionists to help nurses and GPs.

Adoption by patients could be harder to address. There are a few reasons why patients may not want to interact with an AI:
\begin{itemize}
	\item Fear
	\item Unfamiliarity
	\item Lack of empathy from AI
\end{itemize}
At least for the lack of empathy, the research paper "Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum" \cite{bedside} concluded that "a chatbot generated quality and empathetic responses to patient questions posed in an online forum." Hopefully, by their nature, chatbots would offer a more pleasant experience for patients.

\section{Change Management}
It is in people's nature to resist change, which applies to both patients and healthcare staff. As previously stated, cognitive AI should be implemented to work with people rather than replace them.

Implementing cognitive computing within an organization often necessitates significant changes in management approaches. While these changes can lead to improved efficiency and decision-making, they also come with certain drawbacks. Here are some key challenges related to change management when introducing cognitive computing:

\begin{itemize}
\item \textbf{Resistance to Change:} One of the most common fears is job displacement. Implementers must show that while people's jobs will change, they will not be let go.
\item \textbf{Training and Skill Gaps:} Few in healthcare have experience with AI, which can make people reluctant to adopt it.
\item \textbf{Integration Challenges:} Healthcare has many different and incompatible systems. AI can bridge these, but it will take effort.
\item \textbf{Cultural Shifts:} Cognitive computing often requires a shift in organizational culture towards more data-driven decision-making. This can be difficult in a large organization such as healthcare.
\end{itemize}

\section{Lengthy Development Cycles}
AI by its nature has a long lead time before new updates can be released. This means that there can be a significant investment before a product is delivered, and fixes can take a long time to be developed.

\subsection{Advantages}
The healthcare sector is a massive organization that is used to long lead times and expensive projects. It may well turn out that cognitive AI development is on the same timescale that healthcare is already used to or could even be quicker.

\subsection{Disadvantages}
The main disadvantage is that healthcare organizations will likely need to leverage enterprise business relationships they have already created, making it hard for other development teams to compete for work, which may lead to uncompetitive pricing. Cognitive AI also represents a significant change in how people work. Trying to orchestrate this change across many healthcare sectors may be extremely hard or even impossible. Acquiring the correct data for training from many different sectors may also increase the time an AI takes to develop.

Typically, in most software development practices, an iterative approach is preferred where the customer (GPs and patients, in this case) gets to try out early versions to ensure the correct system is being developed. AI does not work this way; it is all or nothing, so it is possible that a lot of time and effort could go into developing something unwanted when delivered.

\break
\bibliography{bibliography}

\end{document}
